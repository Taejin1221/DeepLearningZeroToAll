{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "( x_train, y_train ), ( x_test, y_test ) = mnist.load_data()\n",
    "\n",
    "# Nomalization\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "x_train = tf.cast( x_train, tf.float32 )\n",
    "x_test = tf.cast( x_test, tf.float32 )\n",
    "\n",
    "print( x_train.shape, y_train.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# Reshape\n",
    "x_train = tf.reshape( x_train, [ -1, 784 ] )\n",
    "x_test = tf.reshape( x_test, [ -1, 784 ] )\n",
    "print( x_train.shape, x_test.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# one-hot Encoding\n",
    "y_train = tf.keras.utils.to_categorical( y_train, nb_classes )\n",
    "y_test = tf.keras.utils.to_categorical( y_test, nb_classes )\n",
    "\n",
    "# or\n",
    "# y_train = tf.one_hot( tf.cast( y_train, tf.int32 ), 10 )\n",
    "# y_train = tf.reshape( y_train, [ -1, 10 ] )\n",
    "# y_test = tf.reshape( tf.one_hot( y_test, 10 ), [ -1, 10 ] )\n",
    "\n",
    "print( y_train.shape, y_test.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "num_epochs = 50\n",
    "num_iterations = int( len( x_train ) / batch_size )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable( tf.random.normal( [ 784, nb_classes ] ) )\n",
    "b = tf.Variable( tf.random.normal( [ nb_classes ] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def Hypothesis( X ):\n",
    "    return (  tf.matmul( X, W ) + b )\n",
    "\n",
    "@tf.function\n",
    "def Cost( X, Y ):\n",
    "    return ( tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(\n",
    "            logits = Hypothesis( X ), labels = tf.stop_gradient( Y ) )\n",
    "    ) )\n",
    "\n",
    "def Minimize( X, Y ):\n",
    "    loss = lambda: Cost( X ,Y )\n",
    "    \n",
    "    tf.keras.optimizers.Adam( learning_rate ).minimize( loss, [ W, b ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CorrectPrediction( X, Y ):\n",
    "    return ( tf.equal( tf.argmax( Hypothesis( X ), axis = 1 ),\n",
    "                      tf.argmax( Y, axis = 1 ) ) )\n",
    "\n",
    "def Accuracy( X, Y ):\n",
    "    return ( tf.reduce_mean( tf.cast( CorrectPrediction( X, Y ), tf.float32 ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001, Cost: 4.971765041\n",
      "Epoch: 0002, Cost: 1.494930267\n",
      "Epoch: 0003, Cost: 1.040169477\n",
      "Epoch: 0004, Cost: 0.886379123\n",
      "Epoch: 0005, Cost: 0.812619984\n",
      "Epoch: 0006, Cost: 0.769787967\n",
      "Epoch: 0007, Cost: 0.742399216\n",
      "Epoch: 0008, Cost: 0.723565519\n",
      "Epoch: 0009, Cost: 0.710103571\n",
      "Epoch: 0010, Cost: 0.700298548\n",
      "Epoch: 0011, Cost: 0.692836225\n",
      "Epoch: 0012, Cost: 0.687245727\n",
      "Epoch: 0013, Cost: 0.682766020\n",
      "Epoch: 0014, Cost: 0.679061174\n",
      "Epoch: 0015, Cost: 0.676144719\n",
      "Epoch: 0016, Cost: 0.673806012\n",
      "Epoch: 0017, Cost: 0.671688914\n",
      "Epoch: 0018, Cost: 0.669959843\n",
      "Epoch: 0019, Cost: 0.668563068\n",
      "Epoch: 0020, Cost: 0.667436481\n",
      "Epoch: 0021, Cost: 0.666700900\n",
      "Epoch: 0022, Cost: 0.666157663\n",
      "Epoch: 0023, Cost: 0.665712953\n",
      "Epoch: 0024, Cost: 0.665434897\n",
      "Epoch: 0025, Cost: 0.665210366\n",
      "Epoch: 0026, Cost: 0.665087998\n",
      "Epoch: 0027, Cost: 0.665006697\n",
      "Epoch: 0028, Cost: 0.664994001\n",
      "Epoch: 0029, Cost: 0.665089011\n",
      "Epoch: 0030, Cost: 0.665186226\n",
      "Epoch: 0031, Cost: 0.665223420\n",
      "Epoch: 0032, Cost: 0.665291786\n",
      "Epoch: 0033, Cost: 0.665392637\n",
      "Epoch: 0034, Cost: 0.665481925\n",
      "Epoch: 0035, Cost: 0.665563762\n",
      "Epoch: 0036, Cost: 0.665736198\n",
      "Epoch: 0037, Cost: 0.665931582\n",
      "Epoch: 0038, Cost: 0.666140258\n",
      "Epoch: 0039, Cost: 0.666379809\n",
      "Epoch: 0040, Cost: 0.666608214\n",
      "Epoch: 0041, Cost: 0.666885912\n",
      "Epoch: 0042, Cost: 0.667186022\n",
      "Epoch: 0043, Cost: 0.667517722\n",
      "Epoch: 0044, Cost: 0.667861342\n",
      "Epoch: 0045, Cost: 0.668236256\n",
      "Epoch: 0046, Cost: 0.668628573\n",
      "Epoch: 0047, Cost: 0.669026911\n",
      "Epoch: 0048, Cost: 0.669463933\n",
      "Epoch: 0049, Cost: 0.669928968\n",
      "Epoch: 0050, Cost: 0.670414448\n",
      "Learning finished\n"
     ]
    }
   ],
   "source": [
    "for epoch in range( num_epochs ):\n",
    "    avg_cost = 0\n",
    "    \n",
    "    start_batch, end_batch = 0, batch_size\n",
    "    for iteration in range( num_iterations ):\n",
    "        batch_xs, batch_ys = \\\n",
    "            x_train[ start_batch : end_batch ], y_train[start_batch : end_batch ]\n",
    "        \n",
    "        Minimize( batch_xs, batch_ys )\n",
    "        cost_val = Cost( batch_xs, batch_ys )\n",
    "        \n",
    "        avg_cost += cost_val / num_iterations\n",
    "        \n",
    "        start_batch = start_batch + batch_size\n",
    "        end_batch = end_batch + batch_size\n",
    "    \n",
    "    print( 'Epoch: {:04d}, Cost: {:.9f}'.format( epoch + 1, avg_cost ) )\n",
    "    \n",
    "print( 'Learning finished' )\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9159\r\n"
     ]
    }
   ],
   "source": [
    "tf.print( 'Accuracy: ', Accuracy( x_test, y_test ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  [1]\n",
      "Prediction:  [1]\n"
     ]
    }
   ],
   "source": [
    "r = random.randint( 0, len( x_test ) - 1 )\n",
    "tf.print( 'Label: ', tf.argmax( y_test[ r: r + 1 ], axis = 1 ) )\n",
    "tf.print( \n",
    "    'Prediction: ', tf.argmax(Hypothesis( x_test[ r: r + 1] ), axis = 1 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow( \n",
    "    tf.reshape( x_test[ r: r + 1], [ 28, 28 ] ),\n",
    "    cmap = 'Greys',\n",
    "    interpolation = 'nearest'\n",
    ")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
