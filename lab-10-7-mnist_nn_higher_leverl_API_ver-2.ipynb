{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "( x_train, y_train ), ( x_test, y_test ) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "x_train = x_train.reshape( -1, 784  )\n",
    "x_test = x_test.reshape( -1, 784 )\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical( y_train, 10 )\n",
    "y_test = tf.keras.utils.to_categorical( y_test, 10 )\n",
    "print( x_train.shape, y_train.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "rate = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_output_size = 512\n",
    "final_output_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add( layers.Dense( hidden_output_size, 'relu', input_shape = ( 784, ) ) )\n",
    "model.add( layers.Dropout( rate ) )\n",
    "model.add( layers.Dense( hidden_output_size, 'relu' ) )\n",
    "model.add( layers.Dropout( rate ) )\n",
    "model.add( layers.Dense( hidden_output_size, 'relu' ) )\n",
    "model.add( layers.Dropout( rate ) )\n",
    "model.add( layers.Dense( hidden_output_size, 'relu' ) )\n",
    "model.add( layers.Dropout( rate ) )\n",
    "model.add( layers.Dense( final_output_size, 'softmax' ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.3113 - accuracy: 0.9033\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.1445 - accuracy: 0.9577\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.1093 - accuracy: 0.9686\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0944 - accuracy: 0.9729\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0836 - accuracy: 0.9757\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0736 - accuracy: 0.9789\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0659 - accuracy: 0.9805\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0617 - accuracy: 0.9817\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0600 - accuracy: 0.9825\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0550 - accuracy: 0.9836\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0537 - accuracy: 0.9843\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0499 - accuracy: 0.9852\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0470 - accuracy: 0.9859\n",
      "Epoch 14/15\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0450 - accuracy: 0.9869\n",
      "Epoch 15/15\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0450 - accuracy: 0.9873\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x161c2588cc8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam( learning_rate )\n",
    "model.compile( optimizer, 'categorical_crossentropy', [ 'accuracy' ] )\n",
    "model.fit( x_train, y_train, batch_size, training_epochs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 49us/sample - loss: 0.0712 - accuracy: 0.9837\n",
      "Accuracy:  0.9837\n"
     ]
    }
   ],
   "source": [
    "pred = model.evaluate( x_test, y_test )\n",
    "print( 'Accuracy: ', pred[1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:  [4]\n",
      "prediction:  [4]\n"
     ]
    }
   ],
   "source": [
    "r = random.randint( 0, len( x_test ) - 1 )\n",
    "tf.print( 'label: ', tf.argmax( y_test[ r : r + 1 ], 1 ) )\n",
    "tf.print( 'prediction: ', tf.argmax( model.predict( x_test[ r: r + 1 ] ), 1 ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
